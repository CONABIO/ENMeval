---
title: "ENMeval Vignette"
author: "Robert Muscarella & Jamie M. Kass"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{ENMeval Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, echo = FALSE}
knitr::opts_chunk$set(collapse = TRUE, comment = "#>")
```

## Introduction

`ENMeval` is an R package that performs automated runs and evaluations of ecological niche models, and currently only implements Maxent. `ENMeval` was made for those who want to "tune" their models to maximize predictive ability and avoid overfitting, or in other words, optimizing the balance between goodness-of-fit and model complexity. The primary function `ENMevaluate` does all the heavy lifting and returns a table of evaluation statistics, and for each setting combination (here, colloquially: runs), a model object and prediction raster. There are also parameter options for calculating niche overlap between predictions, running in parallel to speed up computation, and more.

## Demo

We're going to start by downloading an occurrence dataset for *Bradypus variegatus*, the Brown-throated sloth.

```{r}
library(spocc)
bv <- occ('Bradypus variegatus', 'gbif', limit=750, has_coords=TRUE)  # search GBIF for occurrence data
bv.coords <- bv$gbif$data$Bradypus_variegatus[,2:3]  # get the latitude/coordinates for each locality
bv.coords <- bv.coords[!duplicated(bv.coords),]  # remove duplicate rows
```

Let's now get some climate data from WorldClim. We'll download the 19 bioclimatic variables at 10 arcmin resolution, which is about 20 km across at the equator. These climatic data are based on 50-year averages from 1950-2000. Now's also a good time to load the package, as it includes all the downstream dependencies (`raster`, `dismo`, etc.).

```{r, warning=FALSE, message=FALSE}
library(ENMeval)
envs <- getData('worldclim', var='bio', res=10)  # get worldclim bioclimatic variables at 10 arcmin resolution (~20 km at equator) for the world
plot(envs[[1]])  # plot first raster in stack, bio1 (Annual Mean Temperature)
points(bv.coords)  # plot all the occurrence points -- notice the stray point in the ocean, we'll take care of that later
```

Next, we will specify the background extent by cropping (or "clipping" in ArcGIS terms) our global predictor variable rasters to a finer-scale region. As our models compare the environment at occurrence localities to the environment at background localities, we need to sample random points from a background extent. To ensure we do not include areas that are suitable for our species but are unoccupied due to limitations like dispersal constraints, we will conservatively define the background extent as an area surrounding our occurrence localities. We do this by buffering a bounding box that includes all occurrence localities. Other methods of background extent delineation, like minimum convex hulls, are more conservative because they better characterize the geographic space holding the points.

```{r, message=FALSE, fig.width=7, fig.height=5}
bv.coords.sp <- SpatialPoints(bv.coords)  # make a SpatialPoints object
bb <- bbox(bv.coords.sp)  # get the bounding box of the points
bb.buf <- extent(bb[1]-1, bb[3]+1, bb[2]-1, bb[4]+1)  # add 1 degree to each bound (buffer)
envs.backg <- crop(envs, bb.buf)  # crop envs for study extent

# however, we want to remove the Caribbean islands from our extent
library(maptools)
data(wrld_simpl)  # get a simple world countries polygon
ca.sa <- wrld_simpl[wrld_simpl@data$SUBREGION==5|wrld_simpl@data$SUBREGION==13,]  # get polygons for central and south america
bv.coords.sp@proj4string <- crs(ca.sa)  # as both 
bv.coords.sp <- bv.coords.sp[ca.sa]
envs.backg <- mask(envs.backg, ca.sa)  # mask envs
plot(envs.backg[[1]])  
points(bv.coords)  # this is our background extent
```

Here we sample our background points.

```{r}
backg <- randomPoints(envs.backg[[1]], n=10000)  # randomly sample 10,000 background points from one background extent raster (only one per cell without replacement)
points(backg, col='red')  # notice how we have pretty good coverage
```

We'll now take a look at the different partitioning methods offered by `ENMeval`.

```{r}

```

We will now perform model tuning using a variety of complexity combinations. Next, we will isolate the results table from the ENMevaluate object we produce, and using this table determine which model is the best approximation of fitting to the occurrence data without being overly complex. There are a variety of selection-techniques available, but for simplicity, here we will use AICc. We want the model with the lowest AICc score, therefore, we are interested in the model with a delta.AICc of 0. 

```{r}
models <- ENMevaluate(occ = species.coord, env = preds.ext, 
                      method = 'block', categoricals = NULL, 
                      fc = c("L", 'LQ', "H", "LQH"), 
                      bg.coords = backg, RMvalues = seq(1, 5, 0.5), 
                      parallel = TRUE, rasterPreds = TRUE)
results.table<-models@results #Isolate the results table 
results.table #Look at the tuning results. Here, you will find information about omission rates, AUC and AICc scores
best.mod.AICc<- mod.table[mod.table[14]==0][c(1,16)] #Find the row of the results table that has a delta.AICc of 0.
```





## Figures

The figure sizes have been customised so that you can easily put two images side-by-side. 

```{r, fig.show='hold'}
plot(1:10)
plot(10:1)
```

You can enable figure captions by `fig_caption: yes` in YAML:

    output:
      rmarkdown::html_vignette:
        fig_caption: yes

Then you can use the chunk option `fig.cap = "Your figure caption."` in **knitr**.

## More Examples

You can write math expressions, e.g. $Y = X\beta + \epsilon$, footnotes^[A footnote here.], and tables, e.g. using `knitr::kable()`.

```{r, echo=FALSE, results='asis'}
knitr::kable(head(mtcars, 10))
```

Also a quote using `>`:

> "He who gives up [code] safety for [code] speed deserves neither."
([via](https://twitter.com/hadleywickham/status/504368538874703872))
